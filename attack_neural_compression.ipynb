{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WwgCUFnY5DNi"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import io\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_msssim import ssim\n",
        "\n",
        "from typing import List\n",
        "from masks import ring_mask, box_mask, dot_mask\n",
        "from load_compression_models import (\n",
        "    my_bmshj2018_factorized, \n",
        "    my_bmshj2018_factorized_relu,\n",
        "    my_bmshj2018_hyperprior,\n",
        "    my_cheng2020_anchor,\n",
        "    my_cheng2020_attn,\n",
        "    my_mbt2018,\n",
        "    my_mbt2018_mean\n",
        ")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the Compression Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda' \n",
        "elif torch.backends.mps.is_available():\n",
        "    'mps'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4DvnHIr5DK2",
        "outputId": "398a0dfa-6813-4116-e88a-5f9ed633d52a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters: 2998147\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "    'my_bmshj2018_factorized_relu': my_bmshj2018_factorized_relu(quality=2, pretrained=True).train().to(device),\n",
        "    'my_bmshj2018_factorized'     : my_bmshj2018_factorized(quality=2, pretrained=True).train().to(device),\n",
        "    'my_bmshj2018_hyperprior'     : my_bmshj2018_hyperprior(quality=2, pretrained=True).train().to(device),\n",
        "    'my_cheng2020_anchor'         : my_cheng2020_anchor(quality=2, pretrained=True).train().to(device),\n",
        "    'my_cheng2020_attn'           : my_cheng2020_attn(quality=2, pretrained=True).train().to(device),\n",
        "    'my_mbt2018'                  : my_mbt2018(quality=2, pretrained=True).train().to(device),\n",
        "    'my_mbt2018_mean'             : my_mbt2018_mean(quality=2, pretrained=True).train().to(device)\n",
        "}\n",
        "net = models['my_bmshj2018_factorized_relu']\n",
        "print(f'Parameters: {sum(p.numel() for p in net.parameters())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaAtkigqXvSp"
      },
      "source": [
        "### Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdZjl4c55OCQ",
        "outputId": "ce5b24b1-9a24-4e94-b4fd-0e5217354db2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Define the transformations\n",
        "img_size = 256\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the CelebA dataset\n",
        "dataset = datasets.CelebA(root='./data', split='train', transform=transform, download=True)\n",
        "\n",
        "# Create a DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySBsLu7zKW04"
      },
      "source": [
        "### Run Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "iS6L81cBIRKD",
        "outputId": "040401b0-f4a7-43b8-96cc-57d60b862d19"
      },
      "outputs": [],
      "source": [
        "x = dataset[0][0].unsqueeze(0).to(device)\n",
        "\n",
        "num_sources = 2\n",
        "x_hat = [] #dataset[1][0].unsqueeze(0).to(device)\n",
        "for i, (images, label) in enumerate(dataloader):\n",
        "    # num sources must be less than batch size\n",
        "    x_hat = images[:num_sources]\n",
        "    break\n",
        "\n",
        "x_src = x_hat.clone()\n",
        "x_hat.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pgd(\n",
        "        src_img: torch.Tensor, \n",
        "        target_img: torch.Tensor, \n",
        "        model: torch.nn.Module, \n",
        "        optimizer: torch.optim.Optimizer, \n",
        "        scheduler: torch.optim.lr_scheduler.LRScheduler, \n",
        "        num_steps: int, \n",
        "        mask: torch.Tensor = None\n",
        "    ) -> List:\n",
        "    # Get the embedding of the source image and make a copy of the target\n",
        "    src_emb = model.forward(src_img)['y_hat']\n",
        "    target_baseline = target_img.clone()\n",
        "    \n",
        "    # Track the best performance\n",
        "    best_img = None\n",
        "    min_loss = float('inf')\n",
        "    loss_tracker = []\n",
        "\n",
        "    pbar = tqdm(range(num_steps))\n",
        "    for _ in pbar:  \n",
        "        out = model.forward(target_img)\n",
        "        target_emb = out['y_hat']\n",
        "        loss = F.mse_loss(src_emb, target_emb)\n",
        "        pbar.set_description(f\"[Running attack]: Loss {loss.item():.5f}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward(retain_graph=True)\n",
        "        if mask is not None:\n",
        "            target_img.grad = target_img.grad * mask\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        loss_tracker.append(loss.item())\n",
        "\n",
        "        # Save the image that achieved the best performance\n",
        "        if loss.item() < min_loss:\n",
        "            min_loss = loss\n",
        "            best_img = target_img\n",
        "\n",
        "    return best_img, loss_tracker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Running attack]: Loss 0.22666:  55%|█████▍    | 1367/2500 [10:51<09:13,  2.05it/s]"
          ]
        }
      ],
      "source": [
        "# Set hyperparams for mask generation and PGD itself\n",
        "num_steps = 2500\n",
        "mask_type = 'dot'\n",
        "if mask_type == 'box':\n",
        "    lr = 3e-3\n",
        "    mask = box_mask()\n",
        "elif mask_type == 'ring':\n",
        "    lr = 3e-3\n",
        "    num_rings = 50\n",
        "    ring_width = 1\n",
        "    ring_separation = 5\n",
        "    mask = ring_mask(x_hat, num_rings=num_rings, ring_width=ring_width, ring_separation=ring_separation)\n",
        "elif mask_type == 'dot':\n",
        "    lr = 3e-2\n",
        "    vertical_skip = 3\n",
        "    horizontal_skip = 3\n",
        "    mask = dot_mask(x_hat, vertical_skip=vertical_skip, horizontal_skip=horizontal_skip)\n",
        "\n",
        "# Run the attack and produce an adversarial image y_hat\n",
        "optimizer = torch.optim.Adam([x_hat], lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
        "x_adv, loss_tracker = pgd(x, x_hat, model=net, optimizer=optimizer, scheduler=scheduler, num_steps=num_steps, mask=mask)\n",
        "# Pass the adv image through the compression network and see the result\n",
        "output = net.forward(x_adv)['x_hat']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show how the loss changed during optimization\n",
        "plt.plot(loss_tracker)\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.title('Loss Tracker')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a figure to hold the subplots\n",
        "fig, axs = plt.subplots(num_sources, 4, figsize=(num_sources * 5, num_sources * 2))  # num_sources rows, 4 columns\n",
        "labels = ['Target Image', 'Source Image', 'Adv Image', 'Decompressed Adv Image']\n",
        "\n",
        "for idx in range(num_sources):\n",
        "    images = [x, x_src[idx], x_adv[idx], output[idx]]\n",
        "    \n",
        "    # Iterate over the images and axes to plot each image\n",
        "    for img_idx, ax in enumerate(axs[idx]):  # Use idx for outer loop, img_idx for inner\n",
        "        img = images[img_idx].clip(0, 1).squeeze(0).permute(1, 2, 0).detach().numpy()  # Change the shape to [H, W, C]\n",
        "        ax.imshow(img)\n",
        "        if idx == 0:\n",
        "            ax.set_title(labels[img_idx])\n",
        "        ax.axis('off')  # Hide axis\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Performance Metricss\n",
        "\n",
        "Similarity between the adversarial output of the network and the target image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_psnr(img1, img2, max_val=1.0):\n",
        "    # img1 and img2 should be of shape (batch_size, channels, height, width) and normalized to [0, 1] range\n",
        "    mse = F.mse_loss(img1, img2)\n",
        "    psnr = 20 * torch.log10(max_val / torch.sqrt(mse))\n",
        "    return psnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalized_l2_dist = torch.norm(x - output) / (3 * 128 * 128)\n",
        "struct_sim = ssim(x, output)\n",
        "psnr = calculate_psnr(x, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalized_l2_dist, struct_sim, psnr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarity between the source image and the adversarial image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalized_l2_dist = torch.norm(x_src - x_adv) / (3 * 128 * 128)\n",
        "struct_sim = ssim(x_src, x_adv)\n",
        "psnr = calculate_psnr(x_src, x_adv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalized_l2_dist, struct_sim, psnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
